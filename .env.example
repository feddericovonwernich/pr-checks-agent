# GitHub Configuration
GITHUB_TOKEN=ghp_your_github_token_here

# Claude Code Configuration (for repository fixes)
ANTHROPIC_API_KEY=sk-your_anthropic_api_key_here

# LLM Provider Configuration (for decision-making)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2048

# OpenAI Configuration (if using OpenAI provider)
OPENAI_API_KEY=sk-your_openai_api_key_here

# Ollama Configuration (if using Ollama provider)
LLM_BASE_URL=http://localhost:11434

# Telegram Configuration
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here
TELEGRAM_CHAT_ID=your_chat_id_or_channel_here

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# Application Configuration
POLLING_INTERVAL=300
MAX_CONCURRENT_WORKFLOWS=10
MAX_FIX_ATTEMPTS=3
ESCALATION_COOLDOWN=24
WORKFLOW_TIMEOUT=60

# Observability
METRICS_PORT=8080
LOG_LEVEL=INFO

# Optional GitHub Webhook
WEBHOOK_SECRET=your_webhook_secret_here